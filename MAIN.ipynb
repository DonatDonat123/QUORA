{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time, sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "\u001b[1mFeature1: \u001b[07m\u001b[04mBoW\u001b[0m\n",
      "\u001b[1mFeature2: \u001b[07m\u001b[04mCosineSimilarity\u001b[0m\n",
      "\u001b[1mModel: \u001b[07m\u001b[04mRandom Forest\u001b[0m\n",
      "SPLIT DATA\n",
      "LOAD TRAIN DATA\n",
      "TRAIN\n",
      "FIT CORPUS ON COUNT VECTORIZER\n",
      "PROCESSING: COMPUTE COS SIM; PROGRESS 7000 / 7000            \n",
      " FIT RANDOM FOREST\n",
      "PREDICTING\n",
      "RANDOM FOREST PREDICTION IM; PROGRESS 3000 / 3000            \n",
      "\n",
      "EVALUATING\n",
      "SCORE ROC-AUC: 0.631259219898\n",
      "TRAINING ON WHOLE TRAINSET FOR CREATING SUBMISSION FILE\n",
      "LOAD TRAIN DATA FOR PREDICT AND SUBMIT\n",
      "LOAD TRAIN DATA\n",
      "TRAIN\n",
      "LOAD TEST DATA\n",
      "FIT CORPUS ON COUNT VECTORIZER\n",
      "PROCESSING: COMPUTE COS SIM; PROGRESS 10000 / 10000            \n",
      " FIT RANDOM FOREST\n",
      "LOAD TEST DATA\n",
      "PREDICTING\n",
      "RANDOM FOREST PREDICTION IM; PROGRESS 10000 / 10000            \n",
      "\n",
      "Create Submission File\n"
     ]
    }
   ],
   "source": [
    "# Set of feature extractors\n",
    "#\t\t\t key\t  feature class\n",
    "features1 = {\"BoW\": BoW()}\n",
    "features2 = {\"cos\": CosSim()}\n",
    "# Set of classifier models\n",
    "#\t\t   key\t\t  model\n",
    "models = {\"forest\": RandomForest}\n",
    "\n",
    "#TEST\n",
    "DO_feature1_feature2_model(BoW, CosSim, RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DO_feature1_feature2_model(feature1, feature2, model, fitontest=False, ratio = 0.7):\n",
    "    feature1_name, feature2_name, model_name = feature1.name, feature2.name, model.name;\n",
    "    print (\"===========================================================\")\n",
    "    print ('\\033[1mFeature1: \\033[07m\\033[04m' + feature1_name + '\\033[0m')\n",
    "    print ('\\033[1mFeature2: \\033[07m\\033[04m' + feature2_name   + '\\033[0m')\n",
    "    print ('\\033[1mModel: \\033[07m\\033[04m' + model_name   + '\\033[0m')\n",
    "    time.sleep(1)  \n",
    "    # LOAD DATA\n",
    "    X_train, X_traintest, Y_train, Y_traintest = splitData()\n",
    "    # SPLIT AND TEST ON TRAIN DATA\n",
    "        #Train on Train Data (optionallay CountVect also on Test-Set cause unsupervised)\n",
    "    X1_train = X_train.append(X_traintest) # Train unsupervised with whole Training set\n",
    "    X2_train = X_train # Train supervised only with Train Split\n",
    "    f1,f2,cl = Train(X1_train, X2_train, Y_train, feature1, feature2, model, \\\n",
    "                     fitontest = False)\n",
    "        #Predict and Evaluate\n",
    "    pred = Predict(f1, f2, cl, X_traintest)\n",
    "    score = Evaluate(Y_traintest, pred)\n",
    "\n",
    "    # TRAIN ON TRAIN (WITHOUT SPLOT)\n",
    "    print(\"TRAINING ON WHOLE TRAINSET FOR CREATING SUBMISSION FILE\")\n",
    "    XT_train, YT_train = trainData()\n",
    "    f1,f2,cl = Train(XT_train, XT_train, YT_train, feature1, feature2, model, fitontest = True)\n",
    "    # PREDICT SUBMIT FILE\n",
    "    XT, ids = testData()\n",
    "    pred = Predict(f1,f2, cl, XT)\n",
    "    # Create Submission File\n",
    "    PreToSub(ids, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Train(X1_train, X2_train, Y_train, feature1, feature2, model, fitontest = False):\n",
    "    # 1st Stage: Question to Matrix\n",
    "    print(\"TRAIN\")\n",
    "    f1 = feature1()\n",
    "    if(fitontest):\n",
    "        X_test = load_test()\n",
    "        f1.fit(X1_train.append(X_test)) # This douple-appending is a bit ugly but it works\n",
    "    else:\n",
    "        f1.fit(X1_train)\n",
    "    # 2nd Stage: Matrices of 2 Questions to Feature Input for Classifier\n",
    "    f2 = feature2()\n",
    "    X_train = f2.transform(X2_train, f1)\n",
    "    #Train Classifier\n",
    "    cl = model()\n",
    "    cl.fit(X_train, Y_train)\n",
    "    return f1,f2,cl\n",
    "\n",
    "def Predict(f1, f2, cl, X_traintest):\n",
    "    print(\"PREDICTING\")\n",
    "    X_traintest = f2.transform(X_traintest, f1)\n",
    "    pred = cl.predict(X_traintest)\n",
    "    return pred\n",
    "def Evaluate(Y_true, Y_pred):\n",
    "    print(\"EVALUATING\")\n",
    "    score = roc_auc_score(Y_true, Y_pred)\n",
    "    print(\"SCORE ROC-AUC: %s\" %(score))\n",
    "    return score\n",
    "    \n",
    "def PreToSub(ids, pred):\n",
    "    print(\"Create Submission File\")\n",
    "    sub = pd.DataFrame(data={\"test_id\":ids,\"is_duplicate\":pred})\n",
    "    sub.to_csv('sub.csv', columns=['test_id', 'is_duplicate'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Train_Path = './input/df10.csv' # JUST TO TEST FASTER , normally train.csv\n",
    "Test_Path = './input/df10.csv'\n",
    "\n",
    "def load_train():\n",
    "    print(\"LOAD TRAIN DATA\")\n",
    "    train = pd.read_csv(Train_Path).dropna()\n",
    "    return train\n",
    "def load_test():\n",
    "    print(\"LOAD TEST DATA\")\n",
    "    test = pd.read_csv(Test_Path).dropna()\n",
    "    return test\n",
    "def splitData(ratio = 0.7): # ratio = train_set, between 0-1.0, default 0,7\n",
    "    print(\"SPLIT DATA\")\n",
    "    #time.sleep(1)\n",
    "    train = load_train()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(train.loc[:,[\"question1\", \"question2\"]],\\\n",
    "                                                        train[\"is_duplicate\"],\\\n",
    "                                                        train_size=0.7, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "def trainData():\n",
    "    print(\"LOAD TRAIN DATA FOR PREDICT AND SUBMIT\")\n",
    "    train = load_train()\n",
    "    X = train.loc[:, [\"question1\", \"question2\"]]\n",
    "    Y = train.loc[:][\"is_duplicate\"]\n",
    "    return X,Y\n",
    "def testData():\n",
    "    test = load_test()\n",
    "    X_test = test.loc[:,[\"question1\", \"question2\"]]\n",
    "    X_ids = test.loc[:][\"id\"]\n",
    "    return X_test, X_ids\n",
    "\n",
    "def rprint(str): # Next print overwrites this, eg use for indicate progress\n",
    "\tsys.stdout.write(\"PROCESSING: \" + str + \"            \\r\")\n",
    "\tsys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES\n",
    "## 1st Stage: Question to Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoW:\n",
    "    name = \"BoW\"\n",
    "    cv = 0\n",
    "\n",
    "    def fit(self, X):\n",
    "        corpus = pd.concat([X.question1, X.question2])\n",
    "        self.cv = CountVectorizer(analyzer='word',min_df = 0,\n",
    "        max_features=5000, ngram_range=(1,1), preprocessor=None, stop_words=None,\n",
    "        tokenizer=None)\n",
    "        print(\"FIT CORPUS ON COUNT VECTORIZER\")\n",
    "        self.cv.fit(corpus)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.cv.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Stage: Matrices of 2 Questions to Feature Input for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CosSim:\n",
    "    name=\"CosineSimilarity\"\n",
    "    def transform(self, X, cv):\n",
    "        all_csim = []\n",
    "        counter = 0\n",
    "        for index, row in X.iterrows():\n",
    "            counter += 1\n",
    "            a = row[\"question1\"]\n",
    "            b = row[\"question2\"]\n",
    "            similarity = cosine_similarity(cv.transform([a]), cv.transform([b])).ravel()[0]\n",
    "            all_csim.append([similarity])\n",
    "            if (counter%100==0):\n",
    "                rprint(\"COMPUTE COS SIM; PROGRESS %d / %d\" % (counter,len(X)))\n",
    "        return all_csim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    name = \"Random Forest\"\n",
    "    forest = RandomForestClassifier(n_estimators = 100)\n",
    "    def fit(self, X, Y):\n",
    "        print(\"\\n FIT RANDOM FOREST\")\n",
    "        self.forest.fit(X,Y)\n",
    "    def predict(self, X):\n",
    "        print(\"RANDOM FOREST PREDICTION \\n\")\n",
    "        Y = self.forest.predict(X)\n",
    "        return Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
